1. (From Background 1 in prologue) If the decision rule is not linear in X, then the update rule is no longer independent of X ie, it no longer just depends on the weights. In that case, would we also have to learn the exponents of each X to find the optimal decision boundary? How would we go about doing that? On the other hand, if the exponents of each X were fixed, then we would know how much the value of the expression would vary with each change delta in X. For example, for X that we know to be x^2 we know that the corresponding change will always be (w_i * delta^2) so the equation would still be linear in w.

2. (Chapter 1, Looking for structure) Is it a good assumption to make that the ratings for The Godfather are a sum of the ratings for The Shawshank Redemption and The Usual Suspects? I understand that the purpose of this is to demonstrate that there might be hidden relationships between each data points but unless we have evidence for that (or domain knowledge) we should not make this assumption, right? Or would the presence of these relationships between data imply that there is a relationship that we are not aware about?

3. (Chapter 1, 1.3) What does it mean for features to be 'thresholded' or 'have their full resolution' in computing the instance score?

4. (Chapter 1, 1.3, pag 46) When talking about specifc and general features, it was shown that sometimes, choosing general features first is more optimal and sometimes choosing specific features is more optimal. This was described to be dependent on the data we are tring to learn from. But is there any way we can know whether having more specific features is better (or vice versa) before we train the entire model? Can we use cross-validation for this?
